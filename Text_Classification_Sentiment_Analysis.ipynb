{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Classification Sentiment Analysis**"
      ],
      "metadata": {
        "id": "bb7rQcTdw50L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-by-Step Amazon Sentiment Classifier with BERT (PyTorch)"
      ],
      "metadata": {
        "id": "sIupbK_dxKoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jXktQxN_wv4h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from torch.optim import AdamW\n",
        "from datasets import load_dataset\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"GPU available :\", torch.cuda.is_available)\n",
        "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
      ],
      "metadata": {
        "id": "qNWd5CqLw3l-",
        "outputId": "9b449c73-8fda-4273-f915-9da1722b9b45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available : <function is_available at 0x788910f3eca0>\n",
            "Device Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3slA-aw1gKsG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets fsspec"
      ],
      "metadata": {
        "id": "HCqzEJdozuX-",
        "outputId": "160c09c7-c4be-43fc-f1de-00a3f36067a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Amazon Polarity dataset\n",
        "dataset = load_dataset(\"amazon_polarity\")"
      ],
      "metadata": {
        "id": "tIHsfMIrw3Um"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "VXXT7u-5yC-U",
        "outputId": "b7d88050-6708-4b0a-9a54-3b97270696d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['label', 'title', 'content'],\n",
            "        num_rows: 3600000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['label', 'title', 'content'],\n",
            "        num_rows: 400000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take subset for faster experimentation (optional)\n",
        "train_texts = dataset['train']['content'][:20000]\n",
        "train_labels = dataset['train']['label'][:20000]\n",
        "test_texts = dataset['test']['content'][:5000]\n",
        "test_labels = dataset['test']['label'][:5000]\n"
      ],
      "metadata": {
        "id": "6FTXjATdyC7I"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/val split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_text, val_text, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels, test_size=0.1, stratify=train_labels,\n",
        "    random_state=42)"
      ],
      "metadata": {
        "id": "XFTDcD3HyC4k"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "bert = AutoModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "V9m9FrRZyC11"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "def tokenize(texts):\n",
        "    return tokenizer.batch_encode_plus(texts,\n",
        "                                       max_length=128,\n",
        "                                       padding='max_length',\n",
        "                                       truncation=True,\n",
        "                                       return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "jSUMkh9gyCzU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_train = tokenize(train_text)\n",
        "tokens_val = tokenize(val_text)\n",
        "tokens_test = tokenize(test_texts)"
      ],
      "metadata": {
        "id": "i6Qk9h2EyCwp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors\n",
        "train_seq = tokens_train['input_ids']\n",
        "train_mask = tokens_train['attention_mask']\n",
        "train_y = torch.tensor(train_labels)\n",
        "\n",
        "\n",
        "val_seq = tokens_val['input_ids']\n",
        "val_mask = tokens_val['attention_mask']\n",
        "val_y = torch.tensor(val_labels)\n",
        "\n",
        "\n",
        "test_seq = tokens_test['input_ids']\n",
        "test_mask = tokens_test['attention_mask']\n",
        "test_y = torch.tensor(test_labels)"
      ],
      "metadata": {
        "id": "avg4BdWqyCuU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloaders\n",
        "\n",
        "batch_size = 32\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "sHAMkSrCyCrj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6XkmCXhyCo3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVGHtwXiWhLt"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UoCHEKMyWjMB"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FAvzJOOhWhBF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pg3cnLIEWg2R"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWfKg5e1Wgre"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0EtSyfDWgUy"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model Architecture"
      ],
      "metadata": {
        "id": "xu3-QUSQ3Ty0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model Architecture\n",
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)  # For binary classification\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        output = self.bert(sent_id, attention_mask = mask)\n",
        "        cls_hs = output.last_hidden_state[:, 0]\n",
        "        x = self.fc1(cls_hs)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "model = BERT_Arch(bert).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "HT-KATpAyCmJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class weights to handle imbalance\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                     classes=np.unique(train_labels),\n",
        "                                     y=train_labels)\n",
        "\n",
        "weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "\n",
        "# Loss and Optimizer\n",
        "loss_fn = nn.NLLLoss(weight=weights)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "nqErTqjSyCjp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Function**"
      ],
      "metadata": {
        "id": "qxCQ4euULl80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_preds = []\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        sent_id, mask, labels = [b.to(device) for b in batch]\n",
        "        model.zero_grad()\n",
        "\n",
        "        preds = model(sent_id, mask)\n",
        "        loss = loss_fn(preds, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_preds.append(preds.detach().cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "    return avg_loss, total_preds\n"
      ],
      "metadata": {
        "id": "OvaNp27kyChA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eXtmWE3ByCed"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tPaxIcoXWpdG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7n9IqA8ZWpZf"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OnnU-6RqWpW9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Function**"
      ],
      "metadata": {
        "id": "CajK3rUFLsMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_preds = []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        sent_id, mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(sent_id, mask)\n",
        "            loss = loss_fn(preds, labels)\n",
        "            total_loss += loss.item()\n",
        "            total_preds.append(preds.detach().cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "5SCS8AeoyCby"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Lj7gCHsyCZM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the Model**"
      ],
      "metadata": {
        "id": "5Es9Tu03L1H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 3\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "    train_loss, _ = train()\n",
        "    valid_loss, _ = evaluate()\n",
        "    print(f\"Training Loss: {train_loss:.3f}\")\n",
        "    print(f\"Validation Loss: {valid_loss:.3f}\")\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'amazon_sentiment_bert.pt')"
      ],
      "metadata": {
        "id": "BzhHumyVyCWs",
        "outputId": "4a46bfbd-30e4-46b7-d57d-ae6d715099cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3\n",
            "Training Loss: 0.281\n",
            "Validation Loss: 0.239\n",
            "\n",
            "Epoch 2/3\n",
            "Training Loss: 0.159\n",
            "Validation Loss: 0.242\n",
            "\n",
            "Epoch 3/3\n",
            "Training Loss: 0.109\n",
            "Validation Loss: 0.246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BU9HJO1ByCUJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Best Model**"
      ],
      "metadata": {
        "id": "ZCqIGpy3MDYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('amazon_sentiment_bert.pt'))"
      ],
      "metadata": {
        "id": "HAsFpjiayAra",
        "outputId": "616182b3-1c55-4114-c12d-78d94a526374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYuc7LybyAej"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxKjOyB7WvWq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rRsNHBZ_WvOY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGC1nE7hWvLD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**"
      ],
      "metadata": {
        "id": "ITV_6xZbNkDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n",
        "\n",
        "# Create a DataLoader for the test set\n",
        "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=32)\n",
        "\n",
        "# Predict in batches\n",
        "all_preds = []\n",
        "true_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        sent_id, mask, labels = [t.to(device) for t in batch]\n",
        "\n",
        "        outputs = model(sent_id, mask)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\nTest Set Performance:\\n\")\n",
        "print(classification_report(true_labels, all_preds, target_names=[\"Negative\", \"Positive\"]))\n"
      ],
      "metadata": {
        "id": "11qEIeM1yAbO",
        "outputId": "e30494fa-e561-465c-e8ce-b727e19860d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set Performance:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.93      0.90      0.91      2435\n",
            "    Positive       0.91      0.94      0.92      2565\n",
            "\n",
            "    accuracy                           0.92      5000\n",
            "   macro avg       0.92      0.92      0.92      5000\n",
            "weighted avg       0.92      0.92      0.92      5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a7SOHhSlNg7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def predict(text_list):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.batch_encode_plus(text_list,\n",
        "                                         max_length=128,\n",
        "                                         padding='max_length',\n",
        "                                         truncation=True,\n",
        "                                         return_tensors=\"pt\")\n",
        "\n",
        "    input_ids = tokens['input_ids'].to(device)\n",
        "    attention_mask = tokens['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        preds = torch.argmax(probs, axis=1)\n",
        "    return preds.cpu().numpy(), probs.cpu().numpy()\n",
        "\n",
        "# Example inference\n",
        "sample_texts = [\"This product is amazing! I loved it and will buy again.\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predicted_labels, probabilities = predict(sample_texts)\n",
        "\n",
        "for text, label, prob in zip(sample_texts, predicted_labels, probabilities):\n",
        "    label_name = \"Positive\" if label == 1 else \"Negative\"\n",
        "    confidence = prob[label]\n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(f\"Predicted Label: {label_name} (Confidence: {confidence:.2f})\")"
      ],
      "metadata": {
        "id": "9s9llHCKyAYu",
        "outputId": "d0615148-b971-4a64-aef4-4c1d4f8b552f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: This product is amazing! I loved it and will buy again.\n",
            "Predicted Label: Positive (Confidence: 0.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jedAJSMx6XSX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step-by-Step Code: English to Hindi Translation**"
      ],
      "metadata": {
        "id": "XwHdd2CP6baE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a minimal working example using the MarianMT model (Helsinki-NLP/opus-mt-en-hi)"
      ],
      "metadata": {
        "id": "ifNseRF76i3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Load pre-trained MarianMT model and tokenizer for English to Hindi\n",
        "\n",
        "translation_model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "translation_tokenizer = MarianTokenizer.from_pretrained(translation_model_name)\n",
        "translation_model = MarianMTModel.from_pretrained(translation_model_name).to(device)"
      ],
      "metadata": {
        "id": "XmrFlY2r6YeT"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Translation Function**"
      ],
      "metadata": {
        "id": "VpADgGuW7WlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_en_to_hi(text_list):\n",
        "    # Tokenize input texts\n",
        "    inputs = translation_tokenizer(text_list,\n",
        "                       return_tensors=\"pt\",\n",
        "                       padding=True,\n",
        "                       truncation=True,\n",
        "                       max_length=128).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Remove token_type_ids if present (not supported by MarianMT)\n",
        "    if \"token_type_ids\" in inputs:\n",
        "      inputs.pop(\"token_type_ids\")\n",
        "\n",
        "\n",
        "    # Generate translation\n",
        "    with torch.no_grad():\n",
        "        translated_tokens = translation_model.generate(\n",
        "            **inputs,\n",
        "            max_length=128,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    # Decode translations\n",
        "    translated_texts = translation_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
        "    return translated_texts\n"
      ],
      "metadata": {
        "id": "qNkVPuP76YTu"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example English sentences\n",
        "english_sentences = [\n",
        "    \"This product is amazing! I loved it and will buy again.\",\n",
        "    \"Worst purchase ever. Completely useless and waste of money.\",\n",
        "    \"The quality is okay, not too good but acceptable.\"\n",
        "]\n",
        "\n",
        "\n",
        "# Translated to Hindi\n",
        "translated_hindi = translate_en_to_hi(english_sentences)\n",
        "\n",
        "# print results\n",
        "for en, hi in zip(english_sentences, translated_hindi):\n",
        "  print(f\"\\nEnglish: {en}\\nHindi: {hi}\")\n"
      ],
      "metadata": {
        "id": "leqWy3-76YQC",
        "outputId": "61666238-d1e2-4ec8-d933-348b75718178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English: This product is amazing! I loved it and will buy again.\n",
            "Hindi: यह उत्पाद कमाल की बात है!\n",
            "\n",
            "English: Worst purchase ever. Completely useless and waste of money.\n",
            "Hindi: बहुत सारा पैसा बरबाद और बरबाद हो जाता है ।\n",
            "\n",
            "English: The quality is okay, not too good but acceptable.\n",
            "Hindi: यह गुण ठीक है, नहीं भी अच्छा लेकिन स्वीकार्य है ।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GLCdf3iG6YNB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Combine with Sentiment Model**"
      ],
      "metadata": {
        "id": "_nS4SOuW8875"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for text in sample_texts:\n",
        "    label, _ = predict([text])\n",
        "    translated = translate_en_to_hi([text])[0]\n",
        "    sentiment = \"Positive\" if label[0] == 1 else \"Negative\"\n",
        "    print(f\"\\nOriginal: {text}\")\n",
        "    print(f\"Translation: {translated}\")\n",
        "    print(f\"Sentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "id": "xfFax7bD6YKI",
        "outputId": "74e79e30-ea72-40c5-93a2-8d414f3e192b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original: This product is amazing! I loved it and will buy again.\n",
            "Translation: यह उत्पाद कमाल की बात है!\n",
            "Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aS1MqVlv6YG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWU-3Ywl6X7U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}